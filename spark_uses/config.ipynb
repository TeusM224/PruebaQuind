{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install openjdk-11-jdk-headless -qq > /dev/null #Instala la version de Java sobre la que se soporta Spark\n",
    "!wget -q http://apache.osuosl.org/spark/spark-3.2.3/spark-3.2.3-bin-hadoop3.2.tgz #descarga de la pagina de Apache la version de spark 3.2.3 y Hadoop 3.2 (Ambas son de a finales del año pasado)\n",
    "!tar xf spark-3.2.3-bin-hadoop3.2.tgz #Descomprime el archivo\n",
    "!pip install -q findspark #Instala findspark que detecta el programa en la maquina virtual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se configuran las variables de entorno para la ejución de Spark\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.3-bin-hadoop3.2\"\n",
    "\n",
    "\n",
    "\n",
    "# Otra sesion para inicializar, esta es la usada para el proceso de Sentiment Analyst\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer, StopWordsRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una sesión de prueba para verificar que esta funcionando\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "\n",
    "sqlSession = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "sc = SparkContext.getOrCreate()\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appName = \"Sentiment Analysis Maps in Spark\"\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(appName) \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
